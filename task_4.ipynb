{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFzLExWRd9mi"
      },
      "source": [
        "4. Devise a method to locate and identify cards in selected frames from video-001 and\n",
        "video-002. You may want to use one of the matchers you have developed in steps 2 or 3.\n",
        "Validate and demonstrate the performance of your method."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODE HAS BEEN TESTED ON GOOGLE COLAB ON PYTHON VERSION 3.7.12"
      ],
      "metadata": {
        "id": "3kUnMmLsyUDb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M51x4u9aiGvb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing necessary libraries**"
      ],
      "metadata": {
        "id": "F00DlBFhl4yv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce1jXKClhdf3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt                                                   #for plotting images \n",
        "import numpy as np                                                                #library for mathematical operations            \n",
        "from PIL import Image                                                             \n",
        "import glob                                                                       #for reading files\n",
        "import os                                                                         #for performing os operations\n",
        "                    \n",
        "import matplotlib.image as mpimg                                                  \n",
        "import cv2                                                                        #opencv\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX_-w9o3hyRf"
      },
      "outputs": [],
      "source": [
        "data_dir='drive/My Drive/Image_Analysis/DATA/'                                    #data directory path\n",
        "results_dir='drive/My Drive/Image_Analysis/RESULTS_3/'                              #results directory path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd063IF7d_-x"
      },
      "outputs": [],
      "source": [
        "print('Using OpenCV version ', cv2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCla3s6EiBR5"
      },
      "outputs": [],
      "source": [
        "def read_frames(filename):                                                          #function to read frames from video\n",
        "    video_cap = cv2.VideoCapture(filename)                                             \n",
        "\n",
        "    count = 0\n",
        "    frames = []\n",
        "    while True:\n",
        "        success, frame = video_cap.read()\n",
        "\n",
        "        if success:\n",
        "            count += 1\n",
        "            \n",
        "                                                                                    \n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)                          # convert from BGR to RGB format\n",
        "\n",
        "            frames.append(frame)\n",
        "        else:\n",
        "                                                                                  \n",
        "            break;\n",
        "\n",
        "\n",
        "    print('Read ', count, ' frames in total')\n",
        "    video_cap.release()\n",
        "    \n",
        "    return frames\n",
        "\n",
        "def write_frames(frames, filename, codec='MP4V', grey='False', fps=24):               #function to write frames\n",
        "    \n",
        "    print('Writing frames to ', filename)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*codec) # 'MP4V' or 'H264' or 'VP08'/'VP09'\n",
        "    writer = cv2.VideoWriter(filename, fourcc, fps, (frames[0].shape[1],frames[0].shape[0]), True)\n",
        "\n",
        "    \n",
        "    for i in range(0,len(frames)):\n",
        "\n",
        "        \n",
        "        #if (not grey):\n",
        "            #frame = cv2.cvtColor(frames[i], cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        #else:\n",
        "         #   print('gray')\n",
        "          #  frame = cv2.cvtColor(frames[i], cv2.COLOR_GRAY2RGB)\n",
        "        frame= frames[i]\n",
        "        print('writing')\n",
        "        writer.write(frame)\n",
        "\n",
        "    \n",
        "    writer.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To display video in Notebook**"
      ],
      "metadata": {
        "id": "dU5490uzqx9g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wubRKPlqqtii"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def show_video(filename):\n",
        "    \n",
        "    video = io.open(filename, 'rb').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    display(HTML(data='''<video width=\"500\" height=\"240\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /> </video>'''.format(encoded.decode('ascii'))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Video-001**"
      ],
      "metadata": {
        "id": "t7JK_dSModBk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKYvmjDvqwXN"
      },
      "outputs": [],
      "source": [
        "\n",
        "show_video(data_dir + 'video-001.MOV')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAx0E-_FqyqL"
      },
      "outputs": [],
      "source": [
        "# get properties of video\n",
        "\n",
        "video = cv2.VideoCapture(data_dir + 'video-001.MOV')\n",
        "\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "codec = int(video.get(cv2.CAP_PROP_FOURCC))\n",
        "\n",
        "video.release()\n",
        "\n",
        "print('Frames per second (FPS) ', fps)\n",
        "print('Width and height ', width, height)\n",
        "print('Frames count ', frame_count)\n",
        "print('Codec', codec.to_bytes(4, 'little'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read frames from video**"
      ],
      "metadata": {
        "id": "qv2k01IPoYqZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHas48xmq0Zc"
      },
      "outputs": [],
      "source": [
        "#read frames from video\n",
        "\n",
        "frames = read_frames(data_dir + 'video-001.MOV')\n",
        "\n",
        "print(frames[14].shape)                                                            # shape of random frame\n",
        "\n",
        "plt.imshow(frames[14])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing localization and identification of card images** : Before implementing localization, some pre-processing has to be done on frames. Each frame is converted to white background with the same approach as used in task-3 for test card images separation. After getting white background, thresholding and binary conversion of image is done and then bounding boxes are found and localized as done in task-1.\n",
        "For identification, each bounding box is sliced into card image and prediction model obtained from task-3 is run on that image. It returns ID which is displayed in the output-video-001.mov saved in results_dir."
      ],
      "metadata": {
        "id": "oKkEIIp9ovJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(results_dir+'model_predict_ID.h5')                               #loading prediction model to find ID of card"
      ],
      "metadata": {
        "id": "-gUjqrSLA4Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxhTvlrXM4EM"
      },
      "outputs": [],
      "source": [
        "import skimage.exposure\n",
        "from google.colab.patches import cv2_imshow\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "resolution=(256,256)\n",
        "\n",
        "frames_localized=[]\n",
        "for frame in frames:\n",
        "  img_br = frame\n",
        "                                                                                      # convert to hsv\n",
        "  hsv = cv2.cvtColor(img_br,cv2.COLOR_BGR2HSV)\n",
        "                                                                                     \n",
        "  range1 = (20,80,80)\n",
        "  range2 = (90,255,255)\n",
        "  mask = cv2.inRange(hsv,range1,range2)                                                # threshold using inRange\n",
        "  mask = 255 - mask                                                                                \n",
        "  mask = cv2.GaussianBlur(mask, (0,0), sigmaX=3, sigmaY=3, borderType = cv2.BORDER_DEFAULT)  # antialias mask\n",
        "  mask = skimage.exposure.rescale_intensity(mask, in_range=(127.5,255), out_range=(0,255))\n",
        "  result = img_br.copy()\n",
        "  result[mask==0] = (255,255,255)\n",
        "\n",
        "  gray= cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) \n",
        "  thresh= 245\n",
        "  blurred= cv2.GaussianBlur(gray,(5,5),cv2.BORDER_DEFAULT)                            #gaussian blurring \n",
        "  fm = cv2.threshold(blurred, thresh, 255, cv2.THRESH_BINARY_INV)[1]                  #binary thresholding\n",
        "  fm = cv2.convertScaleAbs(fm)\n",
        "  \n",
        "  cnt_mod,_ = cv2.findContours(fm, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)        #find contours\n",
        "  contours=[]\n",
        "\n",
        "  for c in cnt_mod:\n",
        "    if cv2.contourArea(c)>20000:                                                       #if contour area greater than 20000, then keep\n",
        "      contours.append(c)\n",
        "\n",
        "  contours_poly = [None]*len(contours)\n",
        "  boundRect = [None]*len(contours)\n",
        "  \n",
        "  identity=[]\n",
        "\n",
        "  for i, c in enumerate(contours):\n",
        "    contours_poly[i] = cv2.approxPolyDP(c, 3, True)   \n",
        "    boundRect[i] = cv2.boundingRect(contours_poly[i])                                 #create bounding rectangles\n",
        "    x,y,w,h = boundRect[i]                                                            #finding bounding rectangle \n",
        "    roi = frame[y:y+h,x:x+w]                                                          #slicing image using x,y, height, width\n",
        "    roi= cv2.resize(roi,resolution)                                                   \n",
        "    x_test= np.array(roi).astype('float')/255.0                                       #normalized image\n",
        "    x_test = np.reshape(x_test, (1,256,256,3))                                        #reshaped\n",
        "    y_pred_test= model.predict(x_test)                                                #prediction run on card image\n",
        "    y_pred_test = np.argmax(y_pred_test,axis = 1)                                     \n",
        "    identity.append(y_pred_test)                                                      #predicted ID appended to identity \n",
        "  \n",
        "  result= frame.copy()\n",
        "  \n",
        "  #drawing bounding boxes and putting ID for cards\n",
        "  for i in range(len(contours)):                                                                                \n",
        "    color = (255, 0, 0)\n",
        "    cv2.drawContours(result, contours_poly, i, color)                                            \n",
        "    cv2.rectangle(result, (int(boundRect[i][0]), int(boundRect[i][1])),(int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), color, 2)\n",
        "    cv2.putText(result, str(identity[i]), (int(boundRect[i][0]), int(boundRect[i][1])- 10), fontFace = cv2.FONT_HERSHEY_DUPLEX, fontScale = 1.0, color = (125, 246, 55),thickness = 3)\n",
        "\n",
        "  frames_localized.append(result)                                                     #frames appended\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(frames_localized)"
      ],
      "metadata": {
        "id": "MitCjUOHuQ1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(frames_localized[14])"
      ],
      "metadata": {
        "id": "4MC1hRTTnRlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**output_video_001.mov saved to results_dir**"
      ],
      "metadata": {
        "id": "v2D8LCTrnJEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(results_dir+'output_video_001.avi', fourcc, 30, (1080,1920))\n",
        "\n",
        "for frames in frames_localized:\n",
        "  f=cv2.cvtColor(frames, cv2.COLOR_BGR2RGB)\n",
        "  out.write(f)\n",
        "\n",
        "out.release()"
      ],
      "metadata": {
        "id": "VWJ44CQnprUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Video-002**"
      ],
      "metadata": {
        "id": "xLJt2EWElNdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying video in notebook was leading to sometimes session crash, so I have not displayed the video-002 here."
      ],
      "metadata": {
        "id": "Sb5eNajvsV1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#show_video(data_dir + 'video-002.MOV')"
      ],
      "metadata": {
        "id": "KZySqnkjku-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get properties of video\n",
        "\n",
        "video = cv2.VideoCapture(data_dir + 'video-002.MOV')\n",
        "\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "codec = int(video.get(cv2.CAP_PROP_FOURCC))\n",
        "\n",
        "video.release()\n",
        "\n",
        "print('Frames per second (FPS) ', fps)\n",
        "print('Width and height ', width, height)\n",
        "print('Frames count ', frame_count)\n",
        "print('Codec', codec.to_bytes(4, 'little'))"
      ],
      "metadata": {
        "id": "Z_iRWrSDkvrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read frames\n",
        "frames = read_frames(data_dir + 'video-002.MOV')\n",
        "\n",
        "print(frames[100].shape) # shape of frame\n",
        "\n",
        "plt.imshow(frames[200])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9asjv284lEmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Below code can take up to 7-10mins to run as the number of frames are more for video-002. "
      ],
      "metadata": {
        "id": "E7mQOK9awLBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage.exposure\n",
        "from google.colab.patches import cv2_imshow\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "resolution=(256,256)\n",
        "\n",
        "frames_localized=[]\n",
        "for frame in frames:\n",
        "  img_br = frame\n",
        "  # convert to hsv\n",
        "  hsv = cv2.cvtColor(img_br,cv2.COLOR_BGR2HSV)\n",
        "  # threshold using inRange\n",
        "  range1 = (20,80,80)\n",
        "  range2 = (90,255,255)\n",
        "  mask = cv2.inRange(hsv,range1,range2)\n",
        "  mask = 255 - mask\n",
        "  # antialias mask\n",
        "  mask = cv2.GaussianBlur(mask, (0,0), sigmaX=3, sigmaY=3, borderType = cv2.BORDER_DEFAULT)\n",
        "  mask = skimage.exposure.rescale_intensity(mask, in_range=(127.5,255), out_range=(0,255))\n",
        "  result = img_br.copy()\n",
        "  result[mask==0] = (255,255,255)\n",
        "  gray= cv2.cvtColor(result, cv2.COLOR_BGR2GRAY) \n",
        "  thresh= 245\n",
        "  blurred= cv2.GaussianBlur(gray,(5,5),cv2.BORDER_DEFAULT)                            #gaussian blurring \n",
        "  fm = cv2.threshold(blurred, thresh, 255, cv2.THRESH_BINARY_INV)[1]                  #binary thresholding\n",
        "  fm = cv2.convertScaleAbs(fm)\n",
        "  cnt_mod,_ = cv2.findContours(fm, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)        #find contours\n",
        "  contours=[]\n",
        "\n",
        "  for c in cnt_mod:\n",
        "    if cv2.contourArea(c)>20000:                                                       #if contour area greater than 20000, then keep\n",
        "      contours.append(c)\n",
        "\n",
        "  contours_poly = [None]*len(contours)\n",
        "  boundRect = [None]*len(contours)\n",
        "  \n",
        "  identity=[]\n",
        "\n",
        "  for i, c in enumerate(contours):\n",
        "    contours_poly[i] = cv2.approxPolyDP(c, 3, True)   \n",
        "    boundRect[i] = cv2.boundingRect(contours_poly[i])                                 #create bounding rectangles\n",
        "    x,y,w,h = boundRect[i]                                                            #finding bounding rectangle \n",
        "    roi = frame[y:y+h,x:x+w]                                                          #slicing image using x,y, height, width\n",
        "    roi= cv2.resize(roi,resolution)\n",
        "    x_test= np.array(roi).astype('float')/255.0\n",
        "    x_test = np.reshape(x_test, (1,256,256,3))\n",
        "    y_pred_test= model.predict(x_test)\n",
        "    y_pred_test = np.argmax(y_pred_test,axis = 1)\n",
        "    identity.append(y_pred_test)\n",
        "  \n",
        "  drawing = np.zeros((fm.shape[0], fm.shape[1], 3), dtype=np.uint8)\n",
        "  result= frame.copy()\n",
        "        \n",
        "  for i in range(len(contours)):                                                                                \n",
        "    color = (255, 0, 0)\n",
        "    cv2.drawContours(result, contours_poly, i, color)                                            \n",
        "    cv2.rectangle(result, (int(boundRect[i][0]), int(boundRect[i][1])),(int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), color, 2)\n",
        "    cv2.putText(result, str(identity[i]), (int(boundRect[i][0]), int(boundRect[i][1])- 10), fontFace = cv2.FONT_HERSHEY_DUPLEX, fontScale = 1.0, color = (125, 246, 55),thickness = 3)\n",
        "\n",
        "  frames_localized.append(result)\n"
      ],
      "metadata": {
        "id": "mKoT6J81lKmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(frames_localized)"
      ],
      "metadata": {
        "id": "UL7CpbIWmDqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(frames_localized[200])"
      ],
      "metadata": {
        "id": "Rqudqpr4nZUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Writing output_video_002 to results_dir**"
      ],
      "metadata": {
        "id": "nNTKF5rbnacC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(results_dir+'output_video_002.avi', fourcc, 30, (1080,1920))\n",
        "\n",
        "for frames in frames_localized:\n",
        "  f=cv2.cvtColor(frames, cv2.COLOR_BGR2RGB)\n",
        "  out.write(f)\n",
        "\n",
        "out.release()"
      ],
      "metadata": {
        "id": "DzE-DYXcmHIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "task-4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}